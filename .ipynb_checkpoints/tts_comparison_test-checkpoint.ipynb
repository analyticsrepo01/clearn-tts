{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTS Comparison Test: Live API vs Regular TTS API\n",
    "\n",
    "This notebook compares latency and quality between:\n",
    "- Live API (WebSocket-based, gemini-live-2.5-flash-preview-native-audio)\n",
    "- Regular TTS API (REST-based, gemini-2.5-flash-tts)\n",
    "\n",
    "Testing with 3 Indonesian language prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install --upgrade --quiet websockets google-cloud-texttospeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from IPython.display import Audio, Markdown, display\n",
    "import numpy as np\n",
    "from websockets.asyncio.client import connect\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import texttospeech_v1beta1 as texttospeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PROJECT_ID = \"my-project-0004-346516\"\n",
    "LOCATION = \"us-central1\"\n",
    "TTS_LOCATION = \"global\"\n",
    "\n",
    "# Live API configuration\n",
    "HOST = \"us-central1-aiplatform.googleapis.com\"\n",
    "SERVICE_URL = f\"wss://{HOST}/ws/google.cloud.aiplatform.v1.LlmBidiService/BidiGenerateContent\"\n",
    "LIVE_MODEL_ID = \"gemini-live-2.5-flash-preview-native-audio\"\n",
    "LIVE_MODEL = f\"projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/{LIVE_MODEL_ID}\"\n",
    "\n",
    "# Regular TTS configuration\n",
    "TTS_MODEL = \"gemini-2.5-flash-tts\"\n",
    "VOICE = \"Aoede\"\n",
    "LANGUAGE_CODE = \"id-ID\"\n",
    "\n",
    "API_ENDPOINT = (\n",
    "    f\"{TTS_LOCATION}-texttospeech.googleapis.com\"\n",
    "    if TTS_LOCATION != \"global\"\n",
    "    else \"texttospeech.googleapis.com\"\n",
    ")\n",
    "\n",
    "tts_client = texttospeech.TextToSpeechClient(\n",
    "    client_options=ClientOptions(api_endpoint=API_ENDPOINT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get access token for Live API\n",
    "bearer_token = !gcloud auth application-default print-access-token\n",
    "print(\"Access token obtained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test prompts from file\n",
    "with open('test.txt', 'r', encoding='utf-8') as f:\n",
    "    test_prompts = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "print(f\"Loaded {len(test_prompts)} test prompts\\n\")\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"Prompt {i}: {prompt[:100]}...\" if len(prompt) > 100 else f\"Prompt {i}: {prompt}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Live API (WebSocket)\n",
    "\n",
    "Testing all 3 prompts using the Live API with timing measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live API Test Function\n",
    "async def test_live_api(text_input, prompt_num):\n",
    "    start_time = time.time()\n",
    "    start_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    \n",
    "    display(Markdown(f\"### Live API - Prompt {prompt_num}\"))\n",
    "    display(Markdown(f\"**Start Time:** {start_timestamp}\"))\n",
    "    display(Markdown(f\"**Input:** {text_input[:200]}...\"))\n",
    "    \n",
    "    GENERATION_CONFIG = {\n",
    "        \"response_modalities\": [\"AUDIO\"],\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {bearer_token[0]}\",\n",
    "    }\n",
    "    \n",
    "    async with connect(SERVICE_URL, additional_headers=headers) as ws:\n",
    "        # Setup the session\n",
    "        await ws.send(\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"setup\": {\n",
    "                        \"model\": LIVE_MODEL,\n",
    "                        \"generation_config\": GENERATION_CONFIG,\n",
    "                        \"input_audio_transcription\": {},\n",
    "                        \"output_audio_transcription\": {},\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Receive setup response\n",
    "        raw_response = await ws.recv(decode=False)\n",
    "        setup_response = json.loads(raw_response.decode(\"ascii\"))\n",
    "        \n",
    "        # Send text message\n",
    "        msg = {\n",
    "            \"client_content\": {\n",
    "                \"turns\": [{\"role\": \"user\", \"parts\": [{\"text\": text_input}]}],\n",
    "                \"turn_complete\": True,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        request_sent_time = time.time()\n",
    "        await ws.send(json.dumps(msg))\n",
    "        \n",
    "        responses = []\n",
    "        output_transcriptions = []\n",
    "        first_chunk_time = None\n",
    "        \n",
    "        # Receive chunks of server response\n",
    "        async for raw_response in ws:\n",
    "            if first_chunk_time is None:\n",
    "                first_chunk_time = time.time()\n",
    "            \n",
    "            response = json.loads(raw_response.decode())\n",
    "            server_content = response.pop(\"serverContent\", None)\n",
    "            if server_content is None:\n",
    "                break\n",
    "            \n",
    "            if (output_transcription := server_content.get(\"outputTranscription\")) is not None:\n",
    "                if (text := output_transcription.get(\"text\")) is not None:\n",
    "                    output_transcriptions.append(text)\n",
    "            \n",
    "            model_turn = server_content.pop(\"modelTurn\", None)\n",
    "            if model_turn is not None:\n",
    "                parts = model_turn.pop(\"parts\", None)\n",
    "                if parts is not None:\n",
    "                    for part in parts:\n",
    "                        pcm_data = base64.b64decode(part[\"inlineData\"][\"data\"])\n",
    "                        responses.append(np.frombuffer(pcm_data, dtype=np.int16))\n",
    "            \n",
    "            # End of turn\n",
    "            turn_complete = server_content.pop(\"turnComplete\", None)\n",
    "            if turn_complete:\n",
    "                break\n",
    "    \n",
    "    end_time = time.time()\n",
    "    end_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    \n",
    "    total_latency = end_time - start_time\n",
    "    time_to_first_chunk = first_chunk_time - request_sent_time if first_chunk_time else None\n",
    "    \n",
    "    display(Markdown(f\"**End Time:** {end_timestamp}\"))\n",
    "    display(Markdown(f\"**Total Latency:** {total_latency:.3f} seconds\"))\n",
    "    if time_to_first_chunk:\n",
    "        display(Markdown(f\"**Time to First Chunk:** {time_to_first_chunk:.3f} seconds\"))\n",
    "    \n",
    "    if responses:\n",
    "        display(Audio(np.concatenate(responses), rate=24000, autoplay=False))\n",
    "    \n",
    "    if output_transcriptions:\n",
    "        display(Markdown(f\"**Output transcription:** {''.join(output_transcriptions)}\"))\n",
    "    \n",
    "    return {\n",
    "        'prompt_num': prompt_num,\n",
    "        'method': 'Live API',\n",
    "        'total_latency': total_latency,\n",
    "        'time_to_first_chunk': time_to_first_chunk,\n",
    "        'start_time': start_timestamp,\n",
    "        'end_time': end_timestamp\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Live API tests\n",
    "live_api_results = []\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    result = await test_live_api(prompt, i)\n",
    "    live_api_results.append(result)\n",
    "    display(Markdown(\"---\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Regular TTS API (REST)\n",
    "\n",
    "Testing all 3 prompts using the regular TTS API with timing measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular TTS API Test Function\n",
    "def test_regular_tts(text_input, prompt_num):\n",
    "    start_time = time.time()\n",
    "    start_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    \n",
    "    display(Markdown(f\"### Regular TTS API - Prompt {prompt_num}\"))\n",
    "    display(Markdown(f\"**Start Time:** {start_timestamp}\"))\n",
    "    display(Markdown(f\"**Input:** {text_input[:200]}...\"))\n",
    "    \n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        name=VOICE, language_code=LANGUAGE_CODE, model_name=TTS_MODEL\n",
    "    )\n",
    "    \n",
    "    # Perform the text-to-speech request\n",
    "    request_sent_time = time.time()\n",
    "    response = tts_client.synthesize_speech(\n",
    "        input=texttospeech.SynthesisInput(text=text_input),\n",
    "        voice=voice,\n",
    "        audio_config=texttospeech.AudioConfig(\n",
    "            audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    end_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    \n",
    "    total_latency = end_time - start_time\n",
    "    \n",
    "    display(Markdown(f\"**End Time:** {end_timestamp}\"))\n",
    "    display(Markdown(f\"**Total Latency:** {total_latency:.3f} seconds\"))\n",
    "    \n",
    "    # Play the generated audio\n",
    "    display(Audio(response.audio_content, autoplay=False))\n",
    "    \n",
    "    return {\n",
    "        'prompt_num': prompt_num,\n",
    "        'method': 'Regular TTS',\n",
    "        'total_latency': total_latency,\n",
    "        'start_time': start_timestamp,\n",
    "        'end_time': end_timestamp\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Regular TTS tests\n",
    "regular_tts_results = []\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    result = test_regular_tts(prompt, i)\n",
    "    regular_tts_results.append(result)\n",
    "    display(Markdown(\"---\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comparison table\n",
    "display(Markdown(\"## Summary Comparison\"))\n",
    "display(Markdown(\"\\n### Latency Results\\n\"))\n",
    "\n",
    "table = \"| Prompt | Live API (s) | Regular TTS (s) | Difference (s) | Faster Method |\\n\"\n",
    "table += \"|--------|--------------|-----------------|----------------|---------------|\\n\"\n",
    "\n",
    "for i in range(len(test_prompts)):\n",
    "    live_latency = live_api_results[i]['total_latency']\n",
    "    regular_latency = regular_tts_results[i]['total_latency']\n",
    "    diff = abs(live_latency - regular_latency)\n",
    "    faster = \"Live API\" if live_latency < regular_latency else \"Regular TTS\"\n",
    "    \n",
    "    table += f\"| {i+1} | {live_latency:.3f} | {regular_latency:.3f} | {diff:.3f} | {faster} |\\n\"\n",
    "\n",
    "# Add average row\n",
    "avg_live = sum(r['total_latency'] for r in live_api_results) / len(live_api_results)\n",
    "avg_regular = sum(r['total_latency'] for r in regular_tts_results) / len(regular_tts_results)\n",
    "avg_diff = abs(avg_live - avg_regular)\n",
    "avg_faster = \"Live API\" if avg_live < avg_regular else \"Regular TTS\"\n",
    "\n",
    "table += f\"| **Average** | **{avg_live:.3f}** | **{avg_regular:.3f}** | **{avg_diff:.3f}** | **{avg_faster}** |\\n\"\n",
    "\n",
    "display(Markdown(table))\n",
    "\n",
    "# Display time to first chunk for Live API\n",
    "display(Markdown(\"\\n### Live API - Time to First Chunk\\n\"))\n",
    "ttfc_table = \"| Prompt | Time to First Chunk (s) |\\n\"\n",
    "ttfc_table += \"|--------|-------------------------|\\n\"\n",
    "\n",
    "for result in live_api_results:\n",
    "    ttfc = result.get('time_to_first_chunk', 'N/A')\n",
    "    ttfc_str = f\"{ttfc:.3f}\" if isinstance(ttfc, float) else ttfc\n",
    "    ttfc_table += f\"| {result['prompt_num']} | {ttfc_str} |\\n\"\n",
    "\n",
    "if all(r.get('time_to_first_chunk') for r in live_api_results):\n",
    "    avg_ttfc = sum(r['time_to_first_chunk'] for r in live_api_results) / len(live_api_results)\n",
    "    ttfc_table += f\"| **Average** | **{avg_ttfc:.3f}** |\\n\"\n",
    "\n",
    "display(Markdown(ttfc_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Key metrics to consider:\n",
    "\n",
    "1. **Total Latency**: Time from request start to complete audio generation\n",
    "2. **Time to First Chunk** (Live API only): How quickly the first audio chunk arrives\n",
    "3. **Voice Quality**: Subjective evaluation (listen to the audio samples above)\n",
    "\n",
    "The Live API's streaming capability means it can start playing audio before the entire response is generated, which can feel faster to end users even if total latency is similar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
